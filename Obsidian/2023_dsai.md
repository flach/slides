---
theme: white
verticalSeparator: vvv
timeForPresentation: 2700
---
<!-- slide bg="[[PeterCartoon-square.jpg]]" data-background-opacity="0.2"-->
# Explainable AI, explained

*with a bit of data science thrown in* <!-- .element: class="fragment"-->
<br><br><br>
### Peter Flach, University of Bristol
<br><br><br>
[[http://flach.github.io/slides/]]
vvv
## Setting the scene 
This is how Kacper Sokol describes explainability in his PhD thesis: 
<style>
	.red-border{
		border: 5px solid red;
	}
</style>
::: block
$$
\texttt{Explainability} = \\
\underbrace{%
\texttt{Reasoning} \left( \texttt{Transparency} |  \texttt{Background Knowledge} \right)%
}_{\textit{understanding}}%
$$
:::<!-- element class="red-border" -->
::: block
"which defines $\texttt{Explainability}$ as the **process** of deriving *understanding* – i.e., extracting meaning – through $\texttt{Reasoning}$ applied to $\texttt{Transparent}$ insights distilled from a data-driven predictive system that are adjusted to the explainee’s $\texttt{Background Knowledge}$." 
::: <!-- .element: class="fragment"-->

[Explainability is in the mind of the beholder (arxiv)](https://arxiv.org/abs/2112.14466)
vvv
## A simple geometric view
![[XAIplot.jpg|400]]
- in black: decision boundary and weight vector <!-- .element: class="fragment"-->
- in red: feature vector of instance currently on the negative side <!-- .element: class="fragment"-->
- in blue: recourse/counterfactual (closest point on decision boundary) <!-- .element: class="fragment"-->
vvv
## LIME and SHAP
Both take a predictive model and an instance, and determine the most important feature contributions. 

- [LIME](https://github.com/marcotcr/lime) (Local Interpretable Model-agnostic Explanations) reproduces the model's prediction in terms of *interpretable features* that can be switched on or off. 
- [SHAP](https://shap.readthedocs.io/en/latest/) is based on the *Shapley value*: the average contribution of a given feature in the context of all possible other features. 

Both should be considered *algorithm schemas*, with many details dependent on the type of data (images, language, tabular), the interpretable features, the sampling strategy, etc.
vvv
## Outline
1. Actionable counterfactuals
2. Explainability for time series
3. XAI tools
4. XAI with probabilities
5. Data science trajectories
---
# Counterfactuals
::: block <!-- element class="red-border fragment"-->
The recourse to be applied to the feature vector in order to change the predicted
class.
:::
::: block <!-- .element: class="fragment"-->
![[RP.jpg|200]] 
This work was led by Rafael Poyiadzi. 
:::
vvv
[FACE: Feasible and Actionable Counterfactual Explanations (AIES 2020)](https://dl.acm.org/doi/10.1145/3375627.3375850)

![[face.png|500]] 
Four counterfactuals for X: 
+ A has low margin; 
+ B is in a low-density region; 
+ C requires crossing a low-density region; 
+ **D is the one found by FACE.** 
vvv
## Example paths found by the FACE algorithm
![[face2.png ]] 
vvv
## From 0 to 8: *MNIST* example
![[mnist0.png]]
![[mnist1.png]]
---
# XAI for time series
![[TS.jpg|200]] <!-- .element: class="fragment"-->

[Sivill and Flach, AISTATS 2022](https://proceedings.mlr.press/v151/sivill22a.html)
| [github](https://github.com/TortySivill/LIMESegment)
| [slideslive](https://slideslive.com/38980514/limesegment-meaningful-realistic-time-series-explanations?ref=recommended)
vvv
## What's special about time series?
1) We need meaningful "super segments".
2) We need to be able to "switch off" segments.
3) We need to be able to define local neighbourhoods through similarity. 
vvv
## Segmenting time series
![[SegmentationDemonstration.png|700]]
Segments and changepoints are constructed by considering similarity relations that preserve adjacency. 
vvv
## Background vs. foreground
![[Perturb_Intution.png]]
::: block <!-- .element: class="fragment"-->
**Background** components are present throughout.
:::
::: block <!-- .element: class="fragment"-->
**Foreground** components can then be "switched off" as required for LIME. 
:::
vvv
## Similarity
![[zero_TS_demonstration.png|800]]
::: block <!-- .element: class="fragment"-->
With *dynamic time warping* the third perturbation is most similar to the original. 
:::
vvv
## Case study on MIMIC
![[sepsis_casestudy_LS.png]]
---
# XAI tools
![[KS.jpg|200]] <!-- .element: class="fragment"-->
Most of this work was led by Kacper Sokol; <br>the FAT Forensics work was funded by Thales UK.
vvv
## FAT forensics
![[figs/academic_software-HCAI.png|400]]
- [*JOSS* paper (2020)](https://joss.theoj.org/papers/10.21105/joss.01904)
- [*Software Impacts* paper (2022)](https://www.softwareimpacts.com/article/S2665-9638(22)00095-1/fulltext)
- [`fat-forensics.org` Toolbox with demos](https://fat-forensics.org/getting_started/)
vvv
## bLIMEy: build LIME yourself
![[figs/blimey.png|800]]

[arxiv](https://arxiv.org/abs/1910.13016)
| [github](https://fat-forensics.org/how_to/transparency/tabular-surrogates.html)
vvv
## XAI Fact Sheets
*A framework for systematic assessment of <br>explainable approaches*

![[taxonomy.png|400]]
- [(Sokol and Flach, AIES 2020)](https://dl.acm.org/doi/abs/10.1145/3351095.3372870)
| [video](https://www.youtube.com/watch?v=Hy8udfSU5dM)
- [Kacper's slides](https://usi.xmlx.io/slides/1_introduction/taxonomy.html)
---
# XAI with probabilities
Ongoing work!  <!-- element class="fragment"-->
vvv
## LIME and probabilities
![[LIMEprobs.png]]<!-- element class="red-border" -->
[(from LIME github repo)](https://github.com/marcotcr/lime)
vvv
## Log-linear models
LIME assumes a linear relationship between features and predicted probabilities. 

*Log-linear* models assume instead that the log-odds (aka logits) are linear in the features. 

Probabilities are obtained via softmax, which is the inverse of the logit function. 
vvv
## From probabilities <br>to log-odds
Term | Expression | Value
----|----|----
*Posterior probability* | $\mathrm{softmax}(x) = \frac{1}{1+e^{-x}} = \hat{p}$ | $0.52$ 
*Posterior odds* | $e^x=\frac{\hat{p}}{1-\hat{p}}$ | $\frac{0.52}{0.48} = 1.083$
*Log-odds* | $x = \ln \frac{\hat{p}}{1-\hat{p}} = \mathrm{logit}(\hat{p})$  | $-0.65+0.73 = 0.08$
vvv
## Additive vs. multiplicative feature attributions
Additive term $\delta$ in logit | Multiplicative term $e^{\delta}$ in odds | $\hat{p}=0.5$ becomes
----|-----|----
0.1 | 1.11 | 0.52
0.4 | 1.49 | 0.60
0.7 | 2.01 | 0.67
1.0 | 2.72 | 0.73
2.0 | 7.39 | 0.88
5.0 | 148 | 0.99
vvv
## ...which is highly non-linear
![[Sigmoid.png]]
vvv
## Logit-LIME®
1) If the model to be explained produces scores in $(-\infty,\infty)$ (e.g., SVM) then work with those. 
2) If the model produces probabilities then convert those to logits first.
3) Train the linear surrogate model to locally replicate the model's scores or logits. 
4) Interpret the weights as factors multiplying the odds. 
vvv
## Ban the boundary!
There is nothing particularly special about $\hat{p}=0.5$. Hence the notion of an **absolute** counterfactual is somewhat misleading. 
::: block <!-- element class="fragment"-->
So a *relative* counterfactual can be defined as 
:::
::: block <!-- element class="red-border fragment"-->
The recourse to be applied to the feature vector in order to change the predicted
~class~
**probability by $p_{\delta}$**.
:::
vvv
## Relative counterfactual
![[XAIplot2.jpg|600]]
<!--Increase $\hat{p}$ by $0.2$. -->
NB. The probability contours imposed by the model need not be parallel. 
---
# From Data Mining to Data Science

<center>![[GT.png]] <!-- .element height="60%" width="60%" --></center>
vvv
## CRISP-DM (1999)

<center>![[Crisp-DM.svg]] <!-- .element height="45%" width="45%" --></center>
vvv
## CRISP-DM evolution

<center>![[EvolutionKDD.svg]] <!-- .element height="75%" width="75%" --></center>
<small>Adapted from G.  Mariscal,  O.  Marban,  and  C.  Fernandez: A  survey  of  datamining and knowledge discovery process models and methodologies, Knowledge Engineering Review 25(2):137-166, 2010.</small>
vvv
## Data takes centre stage

Contemporary Data Science *starts from the data*: 
- We know or suspect there is value in these data, how do we unlock it? 
- What are the possible operations we can apply to the data to unlock and utilise their value?

While moving away from the process the methodology becomes less prescriptive and more inquisitive:
things you **can** do to data rather than things you **should** do to data. 
vvv
## From mining to prospecting

If data mining is like mining for precious metals, Data Science is like *prospecting*: searching for deposits of precious metals where profitable mines can be located. 

Such a prospecting process is fundamentally **exploratory** and can include some of the following activities: 
vvv
## Exploratory Data Science

- *Goal exploration*: finding business goals which can be achieved in a data-driven way.
- *Data source exploration*: discovering new and valuable sources of data.
- *Data value exploration*: finding out what value might be extracted from given data.
- *Result exploration*: relating Data Science results back to the business goals.
- *Narrative exploration*: extracting valuable stories (e.g., visual or textual) from the data.
- *Product exploration*: finding ways to turn the value extracted from the data into a service or app.
vvv
## DST space

<center>![[DSspace.svg]] <!-- .element height="75%" width="100%" --></center>
vvv
## Traversing DST space

<center>![[DSspace:BBVA.svg]] <!-- .element height="75%" width="100%" --></center>
vvv
## A Data Science Trajectory

<center>![[Ex_TourOperator.svg]] <!-- .element height="75%" width="100%" --></center>

- *Goal Exploration*: activity recommender for tourists.
- *Data Value Exploration*: get third-party location data.
- *Data Preparation*: create user-location-activity ratings.
- *Modelling*: train a recommender system.
- *Product Exploration*: explore most appropriate end-user product/presentation.	
vvv
## Looping

<center>![[Ex_Insurance_CustomerProfiling.svg]] <!-- .element height="75%" width="100%" --></center>
vvv
## Not all trajectories require Modelling

<center>
![[Ex_smart_parking_Dubrovnik.svg]] <!-- .element height="100%" width="100%" -->
![[Ex_BBVA_tourism_spending.svg]] <!-- .element height="100%" width="100%" -->
![[Ex_DataProduct.svg]] <!-- .element height="100%" width="100%" -->
</center>
vvv
## CRISP-DM Twenty Years Later:

*From Data Mining Processes to Data Science Trajectories*. 
F Martinez-Plumed, L Contreras-Ochando, C Ferri, J Hernandez-Orallo, M Kull, N Lachiche, MJ Ramirez-Quintana and P Flach. 
[(IEEE TKDE, 2019)](https://ieeexplore.ieee.org/document/8943998)
---
# Wrapping up
vvv
## Take-home messages
+ Approaches such as LIME and SHAP should be considered *algorithm schemas*.
  + There are many devils in the details!
+ Explainability approaches don't always generalise well across data types.
  + What works for images doesn't necessarily work for tabular data, and *vice versa*.
+ We need to take probabilities seriously. 
  + In particular, they are rarely additive. 
vvv
<!-- slide bg="[[PeterCartoon-square.jpg]]" data-background-opacity="0.1"--><grid drag="100 30" drop="top" flow="row" align="stretch">
## Many thanks to...
</grid>
<grid drag="80 30" drop="10 20" flow="row" align="stretch">
Kacper Sokol

Torty Sivill

Rafael Poyiadzi
</grid>
<grid drag="80 30" drop="10 60" flow="row" align="stretch">
Raul Santos-Rodriguez

Matt Clifford

Alex Hepburn
</grid>
<grid drag="80 40" drop="10 15" flow="row" align="stretch">
![[KS.jpg]] <!-- .element: class="fragment"-->
![[TS.jpg]] <!-- .element: class="fragment"-->
![[RP.jpg]] <!-- .element: class="fragment"-->
</grid>
<grid drag="80 40" drop="10 53" flow="row" align="stretch">
![[RSR.jpg]] <!-- .element: class="fragment"-->
![[MC.jpg]] <!-- .element: class="fragment"-->
![[AH.jpg]] <!-- .element: class="fragment"-->
</grid>
vvv
## This research was supported by
- [Thales UK](https://www.thalesgroup.com/en/countries/europe/united-kingdom)
- [The Alan Turing Institute](https://www.turing.ac.uk)
- [TAILOR European Network of Excellence Centres in Trustworthy AI](https://tailor-network.eu)
- [UKRI Centre for Doctoral Training in Interactive AI](https://www.bristol.ac.uk/cdt/interactive-ai/)
- [The CHIST-ERA project REFRAME](https://reframe.icube.unistra.fr/)
